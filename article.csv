PaperID,Title,Abstract,PersonIDList
1018,Peripheral visual information halves attentional choice biases,"A growing body of research has shown that simple choices involve the construction and comparison of values at the time of decision. These processes are modulated by attention in a way that leaves decision makers susceptible to attentional biases. Here we study the role of peripheral visual information on the choice process and on attentional choice biases. We use an eye-tracking experiment where subjects (N=50 adults) make binary choices between food items that are displayed in marked screen ""shelves"" in two conditions: (1) where both items are displayed, and (2) where items are only displayed when subjects fixate within their shelves. We find that removing the nonfixated option approximately doubles the size of the attentional biases. The results show that peripheral visual information is crucial in facilitating good decisions, and suggest that individuals might be influenceable by settings in which only one item is shown at a time, such as e-commerce.",132; 127; 177
1019,A Cellular-Level Account of Classical Conditioning,"Animals learn from experience the value of environmental stimuli to guide their behavior. At the core of conditioning lies the capacity to associate a neural activity pattern induced by an unconditioned stimulus (US) with the pattern arising in response to a conditioned stimulus (CS). Reward-modulated associative synaptic plasticity has been successful in explaining conditioning when the neural representations of behavioral stimuli are unmixed. However this assumption is inconsistent with the fact that neurons - particularly in high-level, cognitive areas - display mixed selectivity. Inspired by experimental findings on the associative power of single cortical pyramidal neurons, we propose a computational model that achieves generic pattern-to-pattern mappings at the population level. Our model incorporates a local learning rule operating in compartmentalized neurons, which mirrors the capacity of cortical pyramidal neurons to implement predictive learning through coincidence detection. The model accounts for a wide gamut of conditioning phenomena, offers a reductionist mechanism for causal inference, and produces experimentally testable predictions. In psychological terms, it corresponds to the stimulus substitution component of classical conditioning.",193; 177
1020,Using Deep Learning tools for fitting Reinforcement Learning Models,"Computational cognitive modeling has advanced our understanding of learning and decision-making. However, the set of models we use is often limited by technical constraints, such as feasibility of model-fitting. Most modeling methods require computing the likelihood of the data under the model (e.g. finding parameters that maximize it). However, many computational models have intractable likelihoods, and workarounds designed for this problem only work on a small subset of models with specific assumptions. To address this issue, we tested a method using deep learning tools to estimate model parameters without estimating intractable likelihoods. Our results show that we can adequately recover parameters using this end-to-end approach. Our work contributes an important new tool to the ongoing development of computational techniques that will enable researchers to consider a broader set of models and develop better theories of complex human cognition. ",179; 201; 121; 120
1021,A Counterfactual Model of Causal Judgments in Double Prevention,"In cases of double prevention--when one event prevents another from preventing an outcome initiated by a productive factor--people tend to judge the productive factor as causal but the double preventer as non-causal. Recent work demonstrated that this tendency can be explained by appealing to people's agreement with and tendency to consider counterfactuals: asking people to imagine the absence of the double preventer decreased their tendency to view the productive factor as more causal than the double-preventer. These effects were well-explained by the Necessity-Sufficiency (NS) model, which instantiates a particular counterfactual account. Here we asked whether another model, the Counterfactual Effect Size (CES) model, could predict the same effects. We found that the CES model indeed predicted these effects, suggesting that the ability of counterfactual theories to predict causal judgments in cases of double prevention is not unique to the NS model.",170; 175; 141
1023,The geometry of cognitive maps under dynamic cognitive control,"Recent work has shown that abstract, non-spatial relationships between task-relevant states or entities are organized into map-like neural representations. Here, we investigate how these map-like representations interact with changing task goals in the context of cognitive control, where the features most relevant to the current goal benefit from top-down biasing. Classic computational neuroscience studies of cognitive control have focused on explicitly presented categorical features rather than map-like representations retrieved from memory, and have typically found facilitation of task-relevant features and suppression/compression of task-irrelevant features. Here, we explore the relationship between cognitive control and the geometry of map-like representations by combining neural network models and fMRI of the same task. Previously, we found that although only one of two task attributes was behaviorally relevant for current decisions, hippocampus (HC), entorhinal cortex (EC), and orbitofrontal cortex (OFC) spontaneously organized pairwise relationships into 2D map-like representations. Consistent with the predictions of the neural-network models, new analyses of the fMRI data show that task-irrelevant dimensions were compressed relative to task-relevant dimensions dynamically as a function of which dimension is currently relevant, in dorsomedial and dorsolateral frontal (DLFC and DMFC) and posterior and medial parietal cortex (PMC). Furthermore, the model's underlying 2D representations were also affected by task demands in a different way: representations were warped along the 2D axis that remains unchanged across conditions requiring focus on each dimension separately. This finding was confirmed by fMRI analyses showing that this same warping phenomenon occurs in the HC, and that the degree of warping was correlated with individual differences in cognitive control. Further simulations showed that this warped geometry reflects the natural tendency of neural networks to learn context-invariant maps, consistent with behavioral and fMRI results. The stronger reactivation of context information in the HC to mitigate the conflicts was associated with the less the warping in the representations across individuals.",172; 204; 182; 164; 168; 114
1027,Different computational strategies for different reinforcement learning problems,"The Rescorla-Wagner rule remains the most popular tool to describe human behavior in reinforcement learning problems. However, several studies have shown that this learning rule is insufficient to fit human flexibility. Therefore, several extensions of the Rescorla-Wagner learning rule have been proposed. Current work investigates three of these extensions on a wide variety of reinforcement learning datasets. Specifically, we investigate the addition of (1) an adaptive learning rate, (2) modularity and (3) hierarchical learning. We observed (AIC) evidence for each additional feature if reward probabilities change in a well-identifiable manner, such as in classic reversal learning tasks. When reward probabilities are stable or when they change in a not well-identifiable manner the Rescorla-Wagner model fits the data best.",195; 196
1029,A Large and Rich EEG Dataset for Modeling Human Visual Object Recognition,"The human brain achieves object recognition by reformatting visual representations along multiple stages of nonlinear operations in the visual ventral stream. Currently, these representations are most well predicted by deep neural networks (DNNs). However, such models require massive amounts of data to properly train, and to the present day there is a lack of brain datasets that extensively sample the neural dynamics of visual object recognition. Here, we collected a large and rich dataset of high temporal resolution electroencephalography (EEG) responses to images of objects on a natural background. This dataset includes 10 participants, each with 82,160 trials spanning 16,740 image conditions. We highlighted its suitability to train randomly initialized DNNs end-to-end to encode the EEG responses to arbitrary input images. We release this dataset as a tool to foster research in visual neuroscience and computer vision. The dataset is available on OSF: https://osf.io/3jk45/.",137; 129; 180; 119
1030,Orthogonal neural encoding of targets and distractors supports cognitive control,"People can flexibly adapt neural information processing to accommodate a wide range of situations. This flexibility may be facilitated by orthogonal neural representations supporting multiple cognitive control signals. We tested representational orthogonality in fMRI using the recently-developed Parametric Attentional Control Task. In dorsal anterior cingulate cortex, we found that task difficulty due to targets vs distractors was orthogonally encoded along an apparent rostrocaudal gradient. In parietal cortex, we found that the strength of target vs distractor information was collinearly and orthogonally represented with medial-lateral differentiation. Across frontoparietal cortex, feature coherence subspaces were aligned with performance subspaces, but feature coherence was only reliably encoded during control-demanding blocks. Together, we find evidence for the neural representations of task variables necessary for multivariate cognitive control.",178; 185
1031,Deep Learning Reveals Non-linear Relationships between EEG and fMRI Dynamics,"fMRI enables non-invasive neuroimaging with high spatial resolution, but analyzing fMRI's hemodynamic data is challenging due to its complex relationship to the underlying neural activity. Deep learning's power to find non-linear relationships makes it particularly suitable for fMRI analyses, with many successful applications in classification of resting-state data. However, few have explored deep learning's potential to generate continuous cross-modal predictions. If deep learning can translate fMRI data to neurophysiological EEG, it could become a promising method for uncovering relationships between hemodynamic changes and neural activity. Here, we demonstrate a proof-of-concept that deep recurrent neural networks can predict sleep EEG delta power from resting-state fMRI on a datapoint-to-datapoint basis, even for out-of-sample subjects, with predictions primarily driven by cortical fMRI dynamics. Supporting the idea that these predictions leverage non-linear information, a cross-correlation analysis revealed that our model outperformed simple linear methods. These results highlight the potential of deep learning to identify complex relationships between hemodynamic fMRI and EEG neural activity that cannot be detected with traditional linear analyses.",145; 232
1032,"Spatially-embedded Recurrent Neural Networks: Bridging common structural and functional findings in neuroscience, including small-worldness, functional clustering in space and mixed selectivity","Brain networks exist in a biophysical world. In this world, the brain as a whole needs to control and navigate its organism within a complex environment, while its constituent neurons must economically balance the resources they use to grow connections. To build and sustain connections, they need to overcome the strain caused by long distances in physical 3D and their own topological space. Due to being exposed to the same basic forces and hence optimization problem, many brains converge on similar features in their structure and function. To observe the effects of these basic forces on a network's optimization process, we introduce the spatially-embedded RNN (seRNN). We find that seRNNs, due to existing in 3D Euclidean and topological space, naturally converge on solving a task using modular small-world networks in which functionally similar units cluster in space and utilise a mixed selective code. This shows (a) how fundamental, but seemingly unrelated, neuroscientific findings can be attributed to a network's biophysical optimization process and (b) how spatially-embedded neural networks can serve as model systems to bridge between structural and functional research communities to move neuroscientific understanding forward.",103; 105; 187; 108; 115; 128
1033,A neural code for probabilities,"Most events in our lives are probabilistic. Estimating their probability is crucial for adaptive behavior. Humans can estimate such probabilities, and even explicitly report their estimate when asked. The neural basis of such probability estimates remains elusive. Here, we found a neural code of probability estimate in humans during a changing probability estimation task. This neural code explains the measured fMRI activity in prefrontal and parietal cortex. It contains a majority of non-linear responses tuned to certain preferred values of probability, which contrast with the mostly linear responses observed for another quantity-the confidence associated with each estimate. This neural code may serve as a basis for probability estimation, which underlies many behaviors.",136; 116; 125; 130; 190; 135
1034,Factorized convolution models for interpreting neuron guided image evolution,"Convolutional neural networks have been extensively used to model neurons in visual systems of primates and rodents. However, as a regression problem, this is ill-posed, because the number of image-response pairs are often far fewer than the visual feature regressors. Because of this, numerous weights could fit the training set equally well. Most of the modelling methods used unsupervised feature reduction and penalized regression to tackle this problem. But this paradigm discards spatial structure of the feature units for the sake of computational efficiency. Because of this, these approaches usually result in an irregular weight structure, making it hard for interpretation and further investigation of visual selectivity. Here we propose to use a correlative model to find the relevant features to the neuron and then use tensor factorization to find the feature and spatial factors corresponding to the model. This is a ""supervised"" feature reduction method, which could be combined with normal penalized regression. This method is as efficient and accurate as previous penalized regression methods in predicting neurons. Moreover, it provides more accurate localization of receptive fields, and benefits interpretation of the preferred feature of neuron. In this manner, we are able to transform a dense ""black-box"" model of visual neurons into a low rank, part-based model, easier to describe and investigate.",199; 174
1036,Category-selective neural responses are integrated in topographically organized convergence sites,"Category-selectivity is a fundamental principle of organization of perceptual brain regions. Human occipitotemporal cortex is subdivided into areas that respond preferentially to faces, bodies, artifacts, and scenes. However, observers need to integrate information about objects from different categories to form a coherent understanding of the world. How is this category integration implemented in the brain? Here we tested the hypothesis that category integration occurs within anatomically localized integration sites. Studying the multivariate interactions between brain regions with fMRI and artificial neural networks, we found that multiple category-selective representations converge in the angular gyrus. Additional analyses revealed a topographic map of cortical areas that integrate different subsets of the categories, indicating that category integration does not occur in a single stage at a centralized location, but at multiple distinct integration sites.",133; 104; 155; 107
1037,An Efficient Search for Novel Behavioral Strategies in a Vast Program Space,"To forage in a changing and uncertain environment, animals need to gather information about hidden states of the world to guide decisions. To understand the strategies that animals use in such settings, typical theoretical approaches combine Bayesian inference and value iteration to derive optimal behavioral policies that maximize total reward given changing beliefs about the environment. However, specifying these beliefs requires infinite numerical precision; with limited resources, this problem is no longer cleanly separable into components of inference and action selection. To understand the space of behavioral policies in this constrained setting, we enumerate and evaluate all possible behavioral programs that can be constructed from just a handful of states. We show that only 65 (1.4%) of the 4492 top-performing programs can be constructed by approximating Bayesian inference; the remaining programs are structurally or even functionally distinct from Bayesian. We develop a novel tree embedding to understand relationships between these programs. This embedding reveals hidden structures within the space of programs-with nearly all of the top-performing programs connected through single mutations-that can be used to efficiently search for good programs via evolutionary algorithms.",158; 142
1039,Lateral Inhibition Facilitates Sequential Learning in a Hippocampus-Inspired Auto-Associator,"Functional and neurobiological characterizations of the hippocampus and its sub-structures have yielded improved theoretical understandings of how the brain implements learning and memory. Despite these advancements, much about how the architecture of these neural structures implement key memory abilities, such as resistance to catastrophic interference, remains to be explored. The present objective is to construct a neural network model imbued with key features of the hippocampus, such as forming latent representations and lateral inhibition, with the hypothesis that resistance to catastrophic interference will be an emergent property of this architecture. We demonstrate that such a model resists catastrophic interference on-par with established benchmarks and incentivizes unique solutions to the computational challenge of simultaneously maintaining new and existing memories.",163; 159
1040,Latent dimensionality scales with the performance of deep learning models of visual cortex,"Deep learning models of brain systems are often characterized by their training paradigms and architectural constraints. An alternative perspective explains neural networks by the geometry of their latent representational manifolds, rendering training procedures and architectures indirect causal factors. Here, we examined deep neural network models of visual cortex in terms of their core geometric properties by quantifying the latent dimensionality of their responses to natural images. We hypothesized that latent dimensionality governs expected model performance when predicting brain activity. We assessed the accuracy of neural networks at predicting image-evoked activity patterns in visual cortex using both monkey electrophysiology and human fMRI. Our findings reveal a striking dimensionality effect, whereby higher-dimensional models produce higher-fidelity predictions of cortical responses to held-out stimuli. This phenomenon runs counter to the prevailing view that hierarchical visual computations compress dimensionality, and it suggests that latent dimensionality is a governing principle of deep learning in visual neuroscience.",131; 113
1043,"Informative associations between feature, spatial, and category selectivity in human visual cortex","Visual cortical populations can be selective for both high-level semantic categories (faces, buildings) and low-level visual features (orientations, spatial positions). The relationship between feature and category selectivity may reflect the distribution of features in natural images, such that neurons are tuned for low-level visual features diagnostic of their preferred category. We evaluate the generality of this hypothesis by asking whether the statistical association between low-level visual features and high-level semantic categories provides a link between feature, spatial, and category selectivity in human visual cortex. Using a large-scale fMRI dataset (Allen et al., 2021) and a voxelwise encoding model based on Gabor features, we find that the distribution of feature and spatial selectivity across voxels within place-, face-, and body-selective ROIs is consistent with the hypothesized roles of these ROIs in high-level visual processing: voxels tend to be tuned for both features and spatial positions that are informative for discriminating their preferred category. These findings suggest that category selectivity in the human brain may reflect the contributions of multiple, hierarchically organized feature spaces.",140; 189; 200
1044,Contextual Influences on the Perception of Motion and Depth,"One of the fundamental tasks of the visual system is to infer the motion and depth of objects based on their 2D retinal images. This is often complicated by the observer's body and eye movements. Depending on the viewing geometry, the combination of retinal image motion and eye movements can be used to perform different computations: summation to compute object motion in the world (""coordinate transformation"", CT); or division for inferring depth of the object (""depth from motion parallax"", MP). We investigated how the same signals, retinal motion and eye movements, mediate the perception of motion and depth under different viewing contexts in both humans and recurrent neural networks. We asked human subjects to estimate the motion and depth of an object while simulating different viewing contexts with optic flow, and we found distinct patterns of biases between the CT and MP contexts. Furthermore, an RNN trained on the same tasks represents task-relevant variables similarly to our previous findings on neural responses in area MT. Our study demonstrates that the interaction between retinal and eye velocities can lead to very different percepts, depending on the interpretation of the viewing context, and our RNN model provides novel predictions for neural representations.",202; 124
1048,Subtractive prediction error is encoded in the human auditory midbrain,"Predictive coding is a leading theoretical framework for understanding sensory processing as statistical inference. Its main tenet is that sensory input is analysed by prediction error units: neural processors that test our internal expectations on the sensory world against the sensory input. Prediction error units encode the difference between the expectations and the actual input, which is used in higher levels of the processing hierarchy to inform updates in our internal beliefs. The encoding of additive prediction error, signals that aim to add unaccounted elements to the internal representations, has been extensively studied before, both in sensory cortices and the subcortical sensory pathways. Whether sensory pathways also encode subtractive prediction error, signals that aim to remove representations of expected percepts that were absent in the sensory input, has not been unambiguously considered before. Here we used human fMRI to measure responses to omissions of sounds for which participants held varying levels of expectations. We used modelling and Bayesian model comparison to compute the posterior probability that neural populations in auditory midbrain and thalamus specifically encoded subtractive prediction error. The results provide first evidence of the encoding of subtractive prediction error in a subcortical sensory pathway, demonstrating that subcortical nuclei partake on the removal of wrong beliefs in high-level cognitive representations.",249; 227; 248; 253
1049,A Characterization of the Neural Representation of Confidence during Probabilistic Learning,"Predicting what will come next in a changing and stochastic world is difficult. However, humans are able to do so based on past observations in a reasonably accurate manner by following the principles of Bayesian inference. In particular, they have a sense of confidence about their predictions and use it to regulate the updates of those predictions. Here, we probed the neural representation of this confidence in human adults during a probability-learning task with 7T fMRI. Participants were shown binary sequences of visual stimuli generated from an abruptly changing Bernoulli process. They covertly estimated the latent item probability and occasionally reported it along with their estimation confidence. We modelled learning with an (Bayesian) ideal model and distinguished prediction (the probability estimate), confidence (the estimate's precision), predictability, and surprise. Participants' reports correlated with those of the ideal observer. Our results unveiled a neural representation of confidence in a fronto-parietal network where the fMRI activity was 1) sensitive to confidence, 2) specifically so with respect to confounds (surprise and predictability), 3) invariant to which item is predicted in the sequence, and 4) functional inasmuch as it overlapped with a representation of surprise (relevant for confidence-weighted updates), and predicted the subjective confidence reports.",211; 218; 237
1051,Bayesian Modeling of Language-Evoked Event-Related Potentials,"Bayesian hierarchical models are well-suited to analyzing the often noisy data from electroencephalography experiments in cognitive neuroscience: these models provide an intuitive framework to account for structures and correlations in the data, and they allow a straightforward handling of uncertainty. In a typical neurolinguistic experiment, event-related potentials show only very small effect sizes and frequentist approaches to data analysis fail to establish the significance of some of these effects. Here, we present a Bayesian approach to analyzing event-related potentials using as an example data from an experiment which relates word surprisal and neural response. Our model is able to estimate the effect of word surprisal on most components of the event-related potential and provides a richer description of the data. The Bayesian framework also allows easier comparison between estimates based on surprisal values calculated using different language models.",251; 222
1054,Learning Invariant Object Representations through Local Prediction Error Minimization in a Model of Generative Vision,"The visual processing stream is capable of both inferring object identity under changes of viewing conditions, and of using object knowledge to fill in for missing sensory information. Current models of invariant recognition process information in a feedforward manner, leaving the question open how the top-down pathway is trained. Here, we show that predictive coding networks as a model of generative perception acquire object representations invariant to rotational angle, scale and lateral position when trained on sequences of continuously moving objects. The network reconstructs whole images from partially occluded inputs akin to observed decodability of occluded scene information in human early visual areas, which can only be addressed by models with information-carrying recurrent connections. Furthermore, the resulting dynamics of error-encoding neurons in the model provide a novel angle for experimental research on neural encoding of prediction errors.",212; 208; 236; 243
1055,Humans imperfectly recruit reward systems as they learn to achieve novel goals,"Transient goals are key motivators in human learning. Extending the classic reinforcement learning framework to include a flexible mapping of outcomes to rewards according to current goals accounts for goals as intrinsic reinforcers. However, learning by encoding transient goals as rewards is slower than learning with familiar rewards. Here, we test whether this effect is due to occasional lapses in goal encoding and the subsequent value updating. We tasked human participants with learning from both familiar rewards (the ""Points"" condition) and abstract novel ""goal"" images (the ""Goals"" condition). To detect lapses in goal encoding, we asked participants to report all positive outcomes they received. Behavioral results replicated our previous finding that people learn less efficiently when they encode goals as rewards than directly receiving familiar rewards. However, our modeling analysis suggested that lapses could not fully explain this behavioral discrepancy. This finding challenges the hypothesis that lapses are the primary cause of slower goal-driven learning, providing insights into the complex cognitive mechanisms of how humans learn from flexible, goal-dependent value assignments.",239; 214
1057,Different Brain Mechanisms of Time Estimation Depending on Situational Information,"Although we do not always measure time, we can estimate the passage of time based on our previous experience. However, it is unclear how the brain estimates the passage of time without explicit measures. We hypothesized that people use situational information to compensate for missing time. Using Bayesian hierarchical modeling and functional magnetic resonance imaging, we aimed to probe how our brain estimates time with/without situational information. As a result, the frontal lobe is actively involved in time estimation with situational information. The cerebellum and hippocampus were significantly activated in estimating time without situational information. We suggest that the frontal lobe plays a vital role in time estimation to control attentional modulation and time-based prospective memory with situational information. In contrast, the cerebellum and the hippocampus seem to act as an internal clock since these regions were involved in the relatively pure estimation of the time.",242; 225
1058,Modality specificity and generality in the hierarchical levels of cognitive control,"The prefrontal cortex (PFC) is organized hierarchically along a posterior-to-anterior axis. This theoretical framework has been studied mostly using visual stimuli. Here, we investigated this functional organization of the PFC, particularly using multiple sensory information with multivoxel pattern analysis (MVPA) and functional connectivity (FC). We used two different sensory modalities-auditory cues and visual targets-to establish different levels of hierarchical processing. We found that the posterior-to-anterior pattern of activations along the precentral gyrus (PreCG), inferior frontal gyrus (IFG), and middle frontal gyrus (MFG) was observed as the level of hierarchy increased. Furthermore, MVPA results showed that the more anterior regions specifically encoded information for higher-level processing. More interestingly, sensory areas had stronger FC with the posterior region of the PFC than the anterior region. We suggest that the PFC is functionally associated with sensory modality showing posterior-to-anterior gradient system.",255; 225
1060,ConvNets Develop Characteristics of Visual Cortex when Receiving Retinal Input,"Convolutional neural networks exhibit organizational principles of early visual areas. However, they still lack several important characteristics such as cortical magnification, eccentricity-dependence of receptive field sizes and spatial frequency tuning, as well as radial bias. We suggest that these properties arise from the non-uniform sampling of external space that results from the distribution of ganglion cells in the retina. To test this conjecture, we introduce the retinal sampling layer (RSL) which resamples images according to retinal ganglion cell density, before feeding them into the CORnet-Z architecture. Training the network on natural images resulted in it developing all of the hypothesized characteristics.",216; 230; 220; 247
1061,Do Convolutional Neural Networks Model Inferior Temporal Cortex Because of Perceptual or Semantic Features?,"Convolutional neural networks (CNNs) have proven a valuable model of the inferior temporal cortex (IT) of the human brain. One seductive explanation is that CNNs and IT have learned similar category-specific image features (henceforth semantic features). However, a recent study found that an untrained neural network with random weights modelled IT just as well as trained networks. This might be because the architecture alone of CNNs causes them to effectively extract basic perceptual features, which are also known to be represented in IT. Alternatively, untrained and trained networks may capture different aspects of IT representation - perceptual and semantic features, respectively. Here we test this hypothesis using mediation models with perceptual and semantic mediators. We find that different networks, and different layers in the same network, capture distinct features of the representation in IT, highlighting the risk of solely using a superficial similarity metric when the aim is to achieve a deeper understanding of representations in the brain and CNNs.",250; 215
1062,On the role of feedback in visual processing: a predictive coding perspective,"Brain-inspired machine learning is gaining increasing consideration, particularly in computer vision. Several studies investigated the inclusion of top-down feedback connections in convolutional networks; however, their functional role remains unclear. Here, we consider deep convolutional networks and implement Predictive Coding (PC) dynamics through feedback connections to perform object recognition under noisy conditions. Then, we interpret the functional role of the predictive feedback by letting the network optimize the corresponding hyper-parameters in various experimental situations. Across different model depths and architectures (3-layer CNN, ResNet18, and EfficientNetB0) and against various types of noise (CIFAR100-C), we find that the network increasingly relies on top-down predictions as the noise level increases. This effect is most prominent at lower layers in deeper networks. Moreover, the accuracy of the network implementing PC dynamics significantly increases over time-steps, compared to its equivalent feed-forward network. Our results provide novel insights relevant to Neuroscience by confirming the computational role of feedback connections in sensory systems, and to Machine Learning by revealing the benefits of PC dynamics in robust computer vision. An extended version of this work is available as preprint at: https://arxiv.org/abs/2106.04225",205; 240; 213; 252
1063,Hierarchical representations of naturalistic social interactions in the lateral visual pathway,"In our daily lives, we quickly and effortlessly perceive features of others' interactions. Extracting these social details is crucial for deciding how to act in the social world, but little is understood about how this is solved in the mind and brain. Recent work has identified a visually-selective region for the presence of a social interaction in posterior superior temporal sulcus (pSTS), but whether and how diverse features of a social interaction (ranging from visual to high-level) are presented in the pSTS or elsewhere in the brain is unknown. To answer this question, we showed participants 250 3-second video clips of naturalistic two-person interactions while undergoing fMRI. We used an encoding model approach to model where visual and social features of the videos are represented in the brain. We replicate known preference for scene and object features in visual cortex. We also find preference for facing bodies in EBA and joint action in pSTS, extending prior findings with controlled stimuli to natural settings. Finally, we identify regions along the extent of the STS that show a preference for third-party communication. Together, these results suggest a hierarchy of visual to social feature processing along the lateral surface of the brain.",235; 210; 223
1064,Dissociation Between The Use of Implicit and Explicit Priors in Bayesian Perceptual Inference ,"Our brain constantly uses prior knowledge that reflects the statistics of our environment to shape our perception. Those statistics can be implicit, not directly observable but learned from observations, or explicit, communicated directly to the observer, especially in humans. Those different origins and mechanisms for acquiring priors may influence perception differently. Here, we manipulated the strength of priors and sensory likelihood to study perceptual inference in both implicit and explicit contexts. Using Bayesian models of learning and decision, we showed that subjects performed worse in the explicit than implicit context because they neglected more the sensory likelihood. The weight of the likelihood was highly correlated between contexts (but different on average) across individuals, but the weight of priors was unrelated. Those results support a dissociation in perceptual inference between the use of implicit vs. explicit priors. Many previous studies reported suboptimality of perceptual inference in healthy subjects or psychiatric disorders; those results could be reinterpreted in light of the implicit-explicit origin of priors. ",207; 237
1066,A multi-level account of the hippocampus from behavior to neurons,"A complete neuroscience requires multi-level theories that address phenomena ranging from higher-level cognitive behaviors to activities within a cell. Unfortunately, we don't have cognitive models of behavior whose components can be decomposed into the neural dynamics that give rise to behavior, leaving an explanatory gap. Inspired by algorithms that capture flocking behavior in birds, we introduce a neural flocking learning rule to coordinates units that collectively form higher-level mental constructs and parallels recurrent hippocampal activity. The decomposed model shows how brain-scale neural populations coordinate to form assemblies encoding concept and spatial representations, and why many neurons are required for robust performance. Our account provides a multi-level explanation for how cognition and symbol-like representations are supported by coordinated neural assemblies formed through learning.",238; 234
1067,Superstitious learning of abstract order from random reinforcement,"Humans and other animals often infer spurious associations among unrelated events. However, such superstitious learning is usually accounted for by conditioned associations, raising the question of whether an animal could develop more complex cognitive structures independent of reinforcement. Here, we tasked monkeys with discovering the serial order of two pictorial sets: a ""learnable"" set in which the stimuli were implicitly ordered and monkeys were rewarded for choosing the higher-rank stimulus and an ""unlearnable"" set in which stimuli were unordered and feedback was random regardless of the choice. We replicated prior results that monkeys reliably learned the implicit order of the learnable set. Surprisingly, the monkeys behaved as though some ordering also existed in the unlearnable set, showing consistent choice preference even under a preference-discouraging reward schedule that gave rewards more frequently to the stimulus that was selected less often. In simulations, a model-free RL algorithm (Q-learning) displayed a degree of consistent ordering among the unlearnable set but, unlike the monkeys, failed to do so under the preference-discouraging reward schedule. Our results suggest that monkeys infer abstract structures from objectively random events using heuristics that extend beyond stimulus-outcome conditional learning to more cognitive model-based learning mechanisms.",226; 224; 221; 219
1068,Automating dynamic community detection by optimizing scalefreeness for resolution parameter selection.,"Rapid network reconfigurations within the brain are essential to our ability to effortlessly act within a complex and dynamic environment. The field of network neuroscience has attempted to capture and estimate these changes within the brain and has proven successful in linking a large variety of behaviors to these dynamics. One of the most successful of these efforts has been in the development and deployment of dynamic community structure detection. However, there still exists a substantial challenge in deploying this (and others) method to data that is highly variable in spatial and temporal resolution of measuring brain dynamics in addition to the inherent elastic nature of the brain. This tutorial will introduce a Python implementation of the generalized Louvain in a dynamic form that optimizes the elasticity of the measurement technique in its implementation. In this tutorial, we will deploy dynamic community detection pipelines within a theoretically driven context of parameter search, and we end the tutorial with an overview of the metrics possible in analysis of brain dynamics derived after distilling the dynamic functional connectivity matrices into discrete network reconfigurations.",233; 245; 206; 241
1069,Representational dynamics of listened and imagined musical sound sequences,"Imagine a song you know by heart. With low effort you could play it vividly in your mind. However, little is known about how the brain represents and holds in mind such musical ""thoughts"". Here, we leverage time-generalized decoding from MEG brain source activations to show that listened and imagined melodies are represented in auditory cortex, thalamus and middle cingulate cortex. Accuracy patterns reveal that during listening and imagining sounds are represented as a melodic group, while during listening they are also represented individually. Opposite brain activation patterns distinguish between melodies during listening compared to imagining. Our work sheds light on the representational dynamics of listened and imagined musical sound sequences.",244; 209; 229; 254
1070,Statistical inference on representational geometries,"Representational similarity analysis is a versatile method for comparing high dimensional models and neural recording data to each other. Here, we introduce a comprehensive new set of methods for statistical model comparison based on predictions of representational geometries. The inference can handle flexible parametrized models and can treat both subjects and conditions as random effects, such that conclusions generalize to the respective populations of subjects and conditions. With crossvalidated representational distance estimators and metric whitened model evaluators, the power for model comparisons approximates that of likelihood-based inference, but rank-based model evaluation is also supported. We validate the inference methods using extensive simulations with deep neural networks and resampling of calcium imaging and functional MRI data. Results demonstrate that the methods are valid and conclusions generalize correctly. These data analysis methods are available in an open-source Python toolbox.",246; 228; 217; 231